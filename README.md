# running-ai-locally
A simple Python project demonstrating how to interact with local AI models using Ollama via both the official library and direct HTTP requests.
